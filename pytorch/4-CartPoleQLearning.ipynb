{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-01-08 00:17:06,558] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02454235 -0.01785042 -0.0492103  -0.03288961]\n",
      "[-0.02489936 -0.2122334  -0.0498681   0.24386989]\n",
      "[-0.02914403 -0.01643595 -0.0449907  -0.06411633]\n",
      "[-0.02947274  0.17930122 -0.04627302 -0.37064777]\n",
      "[-0.02588672 -0.01513382 -0.05368598 -0.09290682]\n",
      "[-0.0261894   0.18071487 -0.05554412 -0.40203271]\n",
      "[-0.0225751   0.37657885 -0.06358477 -0.71169716]\n",
      "[-0.01504352  0.57252096 -0.07781871 -1.0236977 ]\n",
      "[-0.0035931   0.76858826 -0.09829267 -1.33976422]\n",
      "[ 0.01177866  0.96480069 -0.12508795 -1.66151377]\n",
      "[ 0.03107468  1.16113829 -0.15831823 -1.99039914]\n",
      "[ 0.05429744  1.35752648 -0.19812621 -2.32764867]\n",
      "Episode finished after 12 timesteps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "for i_episode in range(1):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "Box(4,)\n",
      "[  4.80000000e+00   3.40282347e+38   4.18879020e-01   3.40282347e+38]\n",
      "[ -4.80000000e+00  -3.40282347e+38  -4.18879020e-01  -3.40282347e+38]\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.8        -3.92727273 -3.05454545 -2.18181818 -1.30909091 -0.43636364\n",
      "  0.43636364  1.30909091  2.18181818  3.05454545  3.92727273  4.8       ]\n",
      "[ 3  6  1 11  8]\n",
      "4\n",
      "[array([-4.8       , -3.42857143, -2.05714286, -0.68571429,  0.68571429,\n",
      "        2.05714286,  3.42857143,  4.8       ]), array([ -3.40282347e+38,  -2.43058819e+38,  -1.45835291e+38,\n",
      "        -4.86117638e+37,   4.86117638e+37,   1.45835291e+38,\n",
      "         2.43058819e+38,   3.40282347e+38]), array([-0.41887902, -0.2991993 , -0.17951958, -0.05983986,  0.05983986,\n",
      "        0.17951958,  0.2991993 ,  0.41887902]), array([ -3.40282347e+38,  -2.43058819e+38,  -1.45835291e+38,\n",
      "        -4.86117638e+37,   4.86117638e+37,   1.45835291e+38,\n",
      "         2.43058819e+38,   3.40282347e+38])]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-2.4, 0, -4.0, 4, 2])\n",
    "bins = np.linspace(-4.8, 4.8, 12)\n",
    "out = np.digitize(x, bins)\n",
    "print(bins)\n",
    "print(out)\n",
    "\n",
    "a = [np.linspace(env.observation_space.low[i], env.observation_space.high[i], 8) for i in range(4)]\n",
    "\n",
    "print(len(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-01-08 00:17:15,789] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0: [-0.01862144  0.03762346 -0.0073345   0.01823664]\n",
      "s1: [-0.01786897 -0.15739254 -0.00696977  0.30859646]\n",
      "Setting Q: \n",
      "s:  [array(4), array(5), array(4), array(5)] s_plus1:  [array(4), array(4), array(4), array(5)]  action:  0  r:  1.0\n",
      "q:  0.0  max_q_splus1:  0.0\n",
      "new q:  0.01\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "\n",
    "# Qlearner for CartPole\n",
    "class QLearner():\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.epsilon = 0.9\n",
    "        self.alpha = 0.01\n",
    "        self.gamma = 0.99\n",
    "        \n",
    "        # get initial state, divide continuous states into discrete bins\n",
    "        self.bins = [np.linspace(env.observation_space.low[i], env.observation_space.high[i], 9) for i in range(4)]\n",
    "        self.s = env.reset()\n",
    "        self.s_bins = [np.digitize(self.s[i], self.bins[i]) for i in range(4)]\n",
    "        \n",
    "        #initialize Q\n",
    "        self.Q = np.zeros((9, 9, 9, 9, 2))\n",
    "#         print(self.bins)\n",
    "        \n",
    "    \n",
    "    def getQ(self, s, action):\n",
    "        return self.Q[s[0], s[1], s[2], s[3], action]\n",
    "    \n",
    "    \n",
    "    def setQ(self, s, s_plus1, action, r):\n",
    "        print(\"Setting Q: \")\n",
    "        print(\"s: \", s, \"s_plus1: \", s_plus1, \" action: \", action, \" r: \", r)\n",
    "        q = self.getQ(s, action)\n",
    "        max_q_splus1 = np.max(self.Q[s_plus1[0], s_plus1[1], s_plus1[2], s_plus1[3]])\n",
    "        print(\"q: \", q, \" max_q_splus1: \", max_q_splus1)\n",
    "        new_q = q + self.alpha * (r + self.gamma * max_q_splus1 - q)\n",
    "        \n",
    "        print(\"new q: \", new_q)\n",
    "        \n",
    "        self.Q[s[0], s[1], s[2], s[3], action] = new_q\n",
    "#         print(self.Q.shape)\n",
    "#         print(self.Q[state[0], state[1], state[2], state[3]])\n",
    "#         print(self.Q[3:6, 3:6, 3:6, 3:6, :])\n",
    "    \n",
    "    \n",
    "    def step(self, epsilon=None):\n",
    "        if not epsilon:\n",
    "            epsilon = self.epsilon\n",
    "        \n",
    "        action = env.action_space.sample()\n",
    "        s_plus1, r, done, _ = env.step(action)\n",
    "        print(\"s0:\", self.s)\n",
    "        print(\"s1:\", s_plus1)\n",
    "        s_bins = [np.digitize(s_plus1[i], self.bins[i]) for i in range(4)]\n",
    "\n",
    "        self.setQ(self.s_bins, s_bins, action, r)\n",
    "        self.s_bins = s_bins\n",
    "        \n",
    "    \n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    def getStats(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def test_qlearner():\n",
    "    qlearner = QLearner(env)\n",
    "    # print(env.reset())\n",
    "    qlearner.step()\n",
    "\n",
    "\n",
    "\n",
    "test_qlearner()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
